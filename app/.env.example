# Server Configuration
PORT=8000
ENV=development

# Security
API_KEY=your-secret-key-here

# Model Configuration
USE_MOCK=false  # Set to 'true' to use mocked inference (for CI/staging without GPU)

# RAG Configuration
TAVILY_API_KEY=your-tavily-api-key-here  # Get from https://tavily.com

# Docker/Registry (for CI/CD)
REGISTRY_IMAGE=ghcr.io/your-username/fastapi-llm-inference
STAGE=staging
